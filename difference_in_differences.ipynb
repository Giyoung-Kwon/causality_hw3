{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "difference-in-differences.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vveitch/causality-tutorials/blob/main/difference_in_differences.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QfZkNLUb4B-p"
      },
      "source": [
        "# Difference-in-Differences Estimation Tutorial\n",
        "\n",
        "A short example on how to estimate the difference-in-differences ATT with 2 period panel data using using machine learning methods.\n",
        "\n",
        "Data from this paper: https://www.aeaweb.org/articles?id=10.1257/000282804322970733\n",
        "\n",
        "In brief: following a terrorist attack on a synagogue in Buenos Aires, additional police officers were stationed on blocks containing Jewish institutions. This provides a natural experiment for the effect of policing on deterring crime. The data includes the number of car thefts in many city blocks the months before and after the increase in policing. Comparing the change in thefts for blocks with Jewish institutions (hence, increased police) to the other blocks gives a measurement. However, blocks with Jewish institutions may differ in significant ways---e.g., they may tend to be better educated or located in certain neighbourhoods. We want to use machine learning methods to control for such potential issues. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dS2X3Bq1-fxE"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy as sp\n",
        "from sklearn import preprocessing\n",
        "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
        "from sklearn.model_selection import KFold, StratifiedKFold, train_test_split\n",
        "from sklearn.metrics import mean_squared_error, log_loss\n",
        "import sklearn\n",
        "import os"
      ],
      "execution_count": 197,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxJ46X9cFJ9X"
      },
      "source": [
        "RANDOM_SEED=42\n",
        "np.random.seed(RANDOM_SEED)"
      ],
      "execution_count": 198,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPbJeayiEs3u"
      },
      "source": [
        "##Load and Format Data\n",
        "\n",
        "We reformat the data so that there is an \"outcome\" column equal to the difference in car thefts after and before the time period, a \"treatment\" column indictaing the presence of a jewish institute, and \"confounders\" denoting variables that may differ between jewish and non-jewish blocks, and which may also affect the change in crime rate. \n",
        "\n",
        "After doing this formatting, the estimation procedure is identical to computing the ATT with a regression adjustment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2AC9TPko-hbt"
      },
      "source": [
        "panel = pd.read_csv('https://raw.githubusercontent.com/vveitch/causality-tutorials/main/data/ditella-crime-2004/DiTella_crime.csv')\n"
      ],
      "execution_count": 199,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "-A1LX6-t-hZD",
        "outputId": "b94e3198-8c72-423d-a01d-7fc26cc26856"
      },
      "source": [
        "panel.head()"
      ],
      "execution_count": 200,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>block</th>\n",
              "      <th>neighbourhood</th>\n",
              "      <th>street</th>\n",
              "      <th>jewish_insitute</th>\n",
              "      <th>public_institution</th>\n",
              "      <th>gas_station</th>\n",
              "      <th>bank</th>\n",
              "      <th>car_thefts</th>\n",
              "      <th>month</th>\n",
              "      <th>education</th>\n",
              "      <th>employment_rate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>870.0</td>\n",
              "      <td>Once</td>\n",
              "      <td>Cordoba</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>10.846611</td>\n",
              "      <td>0.949495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>870.0</td>\n",
              "      <td>Once</td>\n",
              "      <td>Cordoba</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>10.846611</td>\n",
              "      <td>0.949495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>870.0</td>\n",
              "      <td>Once</td>\n",
              "      <td>Cordoba</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>10.846611</td>\n",
              "      <td>0.949495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>870.0</td>\n",
              "      <td>Once</td>\n",
              "      <td>Cordoba</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>10.846611</td>\n",
              "      <td>0.949495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>870.0</td>\n",
              "      <td>Once</td>\n",
              "      <td>Cordoba</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>10.846611</td>\n",
              "      <td>0.949495</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   block neighbourhood   street  ...  month  education  employment_rate\n",
              "0  870.0          Once  Cordoba  ...    4.0  10.846611         0.949495\n",
              "1  870.0          Once  Cordoba  ...    5.0  10.846611         0.949495\n",
              "2  870.0          Once  Cordoba  ...    6.0  10.846611         0.949495\n",
              "3  870.0          Once  Cordoba  ...    7.0  10.846611         0.949495\n",
              "4  870.0          Once  Cordoba  ...    8.0  10.846611         0.949495\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 200
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUpUVabW59bS"
      },
      "source": [
        "# Terrorist attack occurred in July 18, and increased police presence begins July 25. Data before this is before period, and after is after period \n",
        "first_period = panel['month'].isin([4., 5., 6., 71.])\n",
        "panel['first_period']=first_period"
      ],
      "execution_count": 201,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-8dY5W8Q-PJ"
      },
      "source": [
        "# code neighbourhood as integer for later convenience\n",
        "panel['neighbourhood']=panel['neighbourhood'].astype('category').cat.codes"
      ],
      "execution_count": 202,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "ZBR4R-90DmRn",
        "outputId": "a121111a-1d58-4426-dd0c-354c147453d6"
      },
      "source": [
        "# We need to reduce the multiple before and after months in some fashion\n",
        "# There is not a clear canonical way to do this, but an average seems reasonable\n",
        "panel = panel.groupby(['block', 'first_period']).mean()\n",
        "panel = panel.reset_index(level='first_period')\n",
        "panel"
      ],
      "execution_count": 203,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>first_period</th>\n",
              "      <th>neighbourhood</th>\n",
              "      <th>jewish_insitute</th>\n",
              "      <th>public_institution</th>\n",
              "      <th>gas_station</th>\n",
              "      <th>bank</th>\n",
              "      <th>car_thefts</th>\n",
              "      <th>month</th>\n",
              "      <th>education</th>\n",
              "      <th>employment_rate</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>block</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1.0</th>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>25.25</td>\n",
              "      <td>11.919889</td>\n",
              "      <td>0.926594</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1.0</th>\n",
              "      <td>True</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.00</td>\n",
              "      <td>11.919889</td>\n",
              "      <td>0.926594</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2.0</th>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.156250</td>\n",
              "      <td>25.25</td>\n",
              "      <td>11.919889</td>\n",
              "      <td>0.926594</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2.0</th>\n",
              "      <td>True</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.00</td>\n",
              "      <td>11.919889</td>\n",
              "      <td>0.926594</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3.0</th>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.031250</td>\n",
              "      <td>25.25</td>\n",
              "      <td>11.919889</td>\n",
              "      <td>0.926594</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>874.0</th>\n",
              "      <td>True</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.00</td>\n",
              "      <td>10.898485</td>\n",
              "      <td>0.939759</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>875.0</th>\n",
              "      <td>False</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>25.25</td>\n",
              "      <td>10.898485</td>\n",
              "      <td>0.939759</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>875.0</th>\n",
              "      <td>True</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.083333</td>\n",
              "      <td>5.00</td>\n",
              "      <td>10.898485</td>\n",
              "      <td>0.939759</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>876.0</th>\n",
              "      <td>False</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>25.25</td>\n",
              "      <td>10.898485</td>\n",
              "      <td>0.939759</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>876.0</th>\n",
              "      <td>True</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.083333</td>\n",
              "      <td>5.00</td>\n",
              "      <td>10.898485</td>\n",
              "      <td>0.939759</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1752 rows × 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       first_period  neighbourhood  ...  education  employment_rate\n",
              "block                               ...                            \n",
              "1.0           False              0  ...  11.919889         0.926594\n",
              "1.0            True              0  ...  11.919889         0.926594\n",
              "2.0           False              0  ...  11.919889         0.926594\n",
              "2.0            True              0  ...  11.919889         0.926594\n",
              "3.0           False              0  ...  11.919889         0.926594\n",
              "...             ...            ...  ...        ...              ...\n",
              "874.0          True              1  ...  10.898485         0.939759\n",
              "875.0         False              1  ...  10.898485         0.939759\n",
              "875.0          True              1  ...  10.898485         0.939759\n",
              "876.0         False              1  ...  10.898485         0.939759\n",
              "876.0          True              1  ...  10.898485         0.939759\n",
              "\n",
              "[1752 rows x 10 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 203
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APOqpHmrOGzo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "397aa5fc-b7c1-4617-dc99-765a18ceda5f"
      },
      "source": [
        "# now create a version of the data w/ \"outcome\" = after - before thefts, and \n",
        "compact_df = panel[~panel['first_period']]\n",
        "car_thefts = panel['car_thefts'].values\n",
        "compact_df['Y1-Y0']=car_thefts[~panel['first_period']] - car_thefts[panel['first_period']]"
      ],
      "execution_count": 204,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  after removing the cwd from sys.path.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uN-97eQ3FvW5"
      },
      "source": [
        "# format this in a manner sympatico with ATT estimation\n",
        "compact_df = compact_df.reset_index()\n",
        "\n",
        "outcome = compact_df['Y1-Y0']\n",
        "treatment = compact_df['jewish_insitute']\n",
        "confounders = compact_df[['neighbourhood','public_institution', 'gas_station', 'bank', 'education', 'employment_rate']]"
      ],
      "execution_count": 205,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cYl3bRQ4HliO",
        "outputId": "7379f923-f388-400e-8557-3848238cc675"
      },
      "source": [
        "# finally, do some light data cleaning\n",
        "treatment=treatment.astype(int)\n",
        "\n",
        "# scale continuous covariates\n",
        "cont_vars = ['education', 'employment_rate']\n",
        "confounders[cont_vars] = preprocessing.scale(confounders[cont_vars])\n",
        "\n"
      ],
      "execution_count": 206,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py:1734: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  isetter(loc, value[:, i].tolist())\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C576dWRsa3ad"
      },
      "source": [
        "## Specify Nuisance Function Models\n",
        "\n",
        "The next step is to specify models for the conditional expected outcome and propensity score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qyOhSZRQRb8W",
        "outputId": "63ed01b0-48af-41b4-d878-909b06470000"
      },
      "source": [
        "# specify a model for the conditional expected outcome\n",
        "\n",
        "# TODO(victorveitch) the covariates have basically no predictive power, replace this example with something better\n",
        "\n",
        "# make a function that returns a sklearn model for later use in k-folding\n",
        "def make_Q_model():\n",
        "  # return LinearRegression()\n",
        " return RandomForestRegressor(random_state=RANDOM_SEED, n_estimators=100, max_depth=2)\n",
        "Q_model = make_Q_model()\n",
        "\n",
        "# Sanity check that chosen model actually improves test error\n",
        "# A real analysis should give substantial attention to model selection and validation \n",
        "\n",
        "X_w_treatment = confounders.copy()\n",
        "X_w_treatment[\"treatment\"] = treatment\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_w_treatment, outcome, test_size=0.2)\n",
        "Q_model.fit(X_train, y_train)\n",
        "y_pred = Q_model.predict(X_test)\n",
        "\n",
        "test_mse=mean_squared_error(y_pred, y_test)\n",
        "print(f\"Test MSE of fit model {test_mse}\") \n",
        "baseline_mse=mean_squared_error(y_train.mean()*np.ones_like(y_test), y_test)\n",
        "print(f\"Test MSE of no-covariate model {baseline_mse}\")"
      ],
      "execution_count": 207,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test MSE of fit model 0.027801530904389606\n",
            "Test MSE of no-covariate model 0.028564516759592096\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uq6eZEBXbsaI",
        "outputId": "5b82bcee-03a4-48db-8a16-8c68168245b4"
      },
      "source": [
        "# specify a model for the propensity score\n",
        "\n",
        "def make_g_model():\n",
        "#  return LogisticRegression(max_iter=1000)\n",
        "  return RandomForestClassifier(n_estimators=100, max_depth=2)\n",
        "\n",
        "g_model = make_g_model()\n",
        "# Sanity check that chosen model actually improves test error\n",
        "# A real analysis should give substantial attention to model selection and validation \n",
        "\n",
        "X_train, X_test, a_train, a_test = train_test_split(confounders, treatment, test_size=0.2)\n",
        "g_model.fit(X_train, a_train)\n",
        "a_pred = g_model.predict_proba(X_test)[:,1]\n",
        "\n",
        "test_ce=log_loss(a_test, a_pred)\n",
        "print(f\"Test CE of fit model {test_ce}\") \n",
        "baseline_ce=log_loss(a_test, a_train.mean()*np.ones_like(a_test))\n",
        "print(f\"Test CE of no-covariate model {baseline_ce}\")"
      ],
      "execution_count": 208,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test CE of fit model 0.1597166570168377\n",
            "Test CE of no-covariate model 0.16733990853941555\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2RkvV_4_dFWo"
      },
      "source": [
        "## Use cross fitting to get get predicted outcomes and propensity scores for each unit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KA0AsEGJ_X3b"
      },
      "source": [
        "# helper functions to implement the cross fitting\n",
        "\n",
        "def treatment_k_fold_fit_and_predict(make_model, X:pd.DataFrame, A:np.array, n_splits:int):\n",
        "    \"\"\"\n",
        "    Implements K fold cross-fitting for the model predicting the treatment A. \n",
        "    That is, \n",
        "    1. Split data into K folds\n",
        "    2. For each fold j, the model is fit on the other K-1 folds\n",
        "    3. The fitted model is used to make predictions for each data point in fold j\n",
        "    Returns an array containing the predictions  \n",
        "\n",
        "    Args:\n",
        "    model: function that returns sklearn model (which implements fit and predict_prob)\n",
        "    X: dataframe of variables to adjust for\n",
        "    A: array of treatments\n",
        "    n_splits: number of splits to use\n",
        "    \"\"\"\n",
        "    predictions = np.full_like(A, np.nan, dtype=float)\n",
        "    kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=RANDOM_SEED)\n",
        "    \n",
        "    for train_index, test_index in kf.split(X, A):\n",
        "      X_train = X.loc[train_index]\n",
        "      A_train = A.loc[train_index]\n",
        "      g = make_model()\n",
        "      g.fit(X_train, A_train)\n",
        "\n",
        "      # get predictions for split\n",
        "      predictions[test_index] = g.predict_proba(X.loc[test_index])[:, 1]\n",
        "\n",
        "    assert np.isnan(predictions).sum() == 0\n",
        "    return predictions\n",
        "\n",
        "\n",
        "def outcome_k_fold_fit_and_predict(make_model, X:pd.DataFrame, y:np.array, A:np.array, n_splits:int, output_type:str):\n",
        "    \"\"\"\n",
        "    Implements K fold cross-fitting for the model predicting the outcome Y. \n",
        "    That is, \n",
        "    1. Split data into K folds\n",
        "    2. For each fold j, the model is fit on the other K-1 folds\n",
        "    3. The fitted model is used to make predictions for each data point in fold j\n",
        "    Returns two arrays containing the predictions for all units untreated, all units treated  \n",
        "\n",
        "    Args:\n",
        "    model: function that returns sklearn model (that implements fit and either predict_prob or predict)\n",
        "    X: dataframe of variables to adjust for\n",
        "    y: array of outcomes\n",
        "    A: array of treatments\n",
        "    n_splits: number of splits to use\n",
        "    output_type: type of outcome, \"binary\" or \"continuous\"\n",
        "\n",
        "    \"\"\"\n",
        "    predictions0 = np.full_like(A, np.nan, dtype=float)\n",
        "    predictions1 = np.full_like(y, np.nan, dtype=float)\n",
        "    if output_type == 'binary':\n",
        "      kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=RANDOM_SEED)\n",
        "    elif output_type == 'continuous':\n",
        "      kf = KFold(n_splits=n_splits, shuffle=True, random_state=RANDOM_SEED)\n",
        "\n",
        "    # include the treatment as input feature\n",
        "    X_w_treatment = X.copy()\n",
        "    X_w_treatment[\"A\"] = A\n",
        "\n",
        "    # for predicting effect under treatment / control status for each data point \n",
        "    X0 = X_w_treatment.copy()\n",
        "    X0[\"A\"] = 0\n",
        "    X1 = X_w_treatment.copy()\n",
        "    X1[\"A\"] = 1\n",
        "\n",
        "    \n",
        "    for train_index, test_index in kf.split(X_w_treatment, y):\n",
        "      X_train = X_w_treatment.loc[train_index]\n",
        "      y_train = y.loc[train_index]\n",
        "      q = make_model()\n",
        "      q.fit(X_train, y_train)\n",
        "\n",
        "      if output_type =='binary':\n",
        "        predictions0[test_index] = q.predict_proba(X0.loc[test_index])[:, 1]\n",
        "        predictions1[test_index] = q.predict_proba(X1.loc[test_index])[:, 1]\n",
        "      elif output_type == 'continuous':\n",
        "        predictions0[test_index] = q.predict(X0.loc[test_index])\n",
        "        predictions1[test_index] = q.predict(X1.loc[test_index])\n",
        "\n",
        "    assert np.isnan(predictions0).sum() == 0\n",
        "    assert np.isnan(predictions1).sum() == 0\n",
        "    return predictions0, predictions1"
      ],
      "execution_count": 209,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVcE6pRQeMNf"
      },
      "source": [
        "g = treatment_k_fold_fit_and_predict(make_g_model, X=confounders, A=treatment, n_splits=10)"
      ],
      "execution_count": 210,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLEHlLLdWSh9"
      },
      "source": [
        "Q0,Q1=outcome_k_fold_fit_and_predict(make_Q_model, X=confounders, y=outcome, A=treatment, n_splits=10, output_type=\"continuous\")"
      ],
      "execution_count": 211,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "_NVCV0q0g8wQ",
        "outputId": "625e4e9d-8ea4-4e57-c684-6037a4ce3b3f"
      },
      "source": [
        "data_and_nuisance_estimates = pd.DataFrame({'g': g, 'Q0': Q0, 'Q1': Q1, 'A': treatment, 'Y': outcome})\n",
        "data_and_nuisance_estimates.head()"
      ],
      "execution_count": 212,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>g</th>\n",
              "      <th>Q0</th>\n",
              "      <th>Q1</th>\n",
              "      <th>A</th>\n",
              "      <th>Y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.027920</td>\n",
              "      <td>-0.065413</td>\n",
              "      <td>-0.133397</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.027276</td>\n",
              "      <td>-0.070393</td>\n",
              "      <td>-0.118878</td>\n",
              "      <td>0</td>\n",
              "      <td>0.156250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.028456</td>\n",
              "      <td>-0.076041</td>\n",
              "      <td>-0.142226</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.302083</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.028456</td>\n",
              "      <td>-0.065413</td>\n",
              "      <td>-0.133397</td>\n",
              "      <td>0</td>\n",
              "      <td>0.062500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.025655</td>\n",
              "      <td>-0.020747</td>\n",
              "      <td>-0.085449</td>\n",
              "      <td>0</td>\n",
              "      <td>0.062500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          g        Q0        Q1  A         Y\n",
              "0  0.027920 -0.065413 -0.133397  0  0.000000\n",
              "1  0.027276 -0.070393 -0.118878  0  0.156250\n",
              "2  0.028456 -0.076041 -0.142226  0 -0.302083\n",
              "3  0.028456 -0.065413 -0.133397  0  0.062500\n",
              "4  0.025655 -0.020747 -0.085449  0  0.062500"
            ]
          },
          "metadata": {},
          "execution_count": 212
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNhM7URdgzQB"
      },
      "source": [
        "## Combine predicted values and data into estimate of ATT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-vONC5ejwh2"
      },
      "source": [
        "def att_aiptw(Q0, Q1, g, A, Y, prob_t=None):\n",
        "  \"\"\"\n",
        "  # Double ML estimator for the ATT\n",
        "  This uses the ATT specific scores, see equation 3.9 of https://www.econstor.eu/bitstream/10419/149795/1/869216953.pdf\n",
        "  \"\"\"\n",
        "\n",
        "  if prob_t is None:\n",
        "    prob_t = A.mean() # estimate marginal probability of treatment\n",
        "\n",
        "  tau_hat = (A*(Y-Q0) - (1-A)*(g/(1-g))*(Y-Q0)).mean()/ prob_t\n",
        "  \n",
        "  scores = (A*(Y-Q0) - (1-A)*(g/(1-g))*(Y-Q0) - tau_hat*A) / prob_t\n",
        "  n = Y.shape[0] # number of observations\n",
        "  std_hat = np.std(scores) / np.sqrt(n)\n",
        "\n",
        "  return tau_hat, std_hat\n"
      ],
      "execution_count": 213,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SjDj0F9Bm9uq",
        "outputId": "bfbca9bb-c2e0-4171-d65f-bebb71fd0da1"
      },
      "source": [
        "tau_hat, std_hat = att_aiptw(**data_and_nuisance_estimates)\n",
        "print(f\"The estimate is {tau_hat} pm {1.96*std_hat}\")"
      ],
      "execution_count": 214,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The estimate is -0.0777691984649497 pm 0.05810535308191231\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R3YqKD60UElw",
        "outputId": "b4dad931-c970-429e-8c83-ece9db655c9f"
      },
      "source": [
        "# for comparison, the point estimate without any covariate correction\n",
        "outcome[treatment==1].mean()-outcome[treatment==0].mean()"
      ],
      "execution_count": 215,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.06683773314434818"
            ]
          },
          "metadata": {},
          "execution_count": 215
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37ep7LyGUHH9"
      },
      "source": [
        ""
      ],
      "execution_count": 215,
      "outputs": []
    }
  ]
}