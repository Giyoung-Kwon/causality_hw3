{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ATE-Estimation-with-Machine-Learning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vveitch/causality-tutorials/blob/main/ATE_Estimation_with_Machine_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QfZkNLUb4B-p"
      },
      "source": [
        "# ATT Estimation Tutorial\n",
        "\n",
        "This tutorial gives a short example for how to estimate average treatment effect on the treated using machine learning methods"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dS2X3Bq1-fxE"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy as sp\n",
        "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
        "from sklearn.model_selection import KFold, StratifiedKFold, train_test_split\n",
        "from sklearn.metrics import mean_squared_error, log_loss\n",
        "import sklearn\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPbJeayiEs3u"
      },
      "source": [
        "**Load and Format LaLonde Observational Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2AC9TPko-hbt"
      },
      "source": [
        "def make_data_lalonde(df):\n",
        "    df_new = df.drop(['nodegree'], axis=1)\n",
        "    df_new['pos74'] = (df_new['RE74'] > 0).astype(int)\n",
        "    df_new['pos75'] = (df_new['RE75'] > 0).astype(int)\n",
        "    df_new['treatment'] = df_new['treatment'].astype(int)\n",
        "    return df_new\n",
        "\n",
        "\n",
        "col_names = ['treatment', 'age', 'education', 'black',\n",
        "             'hispanic', 'married', 'nodegree', 'RE74', 'RE75', 'RE78']\n",
        "control = pd.read_csv('https://raw.githubusercontent.com/anishazaveri/austen_plots/master/data/imbens-raw/psid_controls.txt', header=None, sep=r\"\\s\\s\", names=col_names, engine='python')\n",
        "treatment = pd.read_csv('https://raw.githubusercontent.com/anishazaveri/austen_plots/master/data/imbens-raw/nswre74_treated.txt', header=None, sep=r\"\\s\\s\", names=col_names, engine='python')\n",
        "\n",
        "lalonde1 = pd.concat([control, treatment]).reset_index(drop=True)\n",
        "lalonde1 = make_data_lalonde(lalonde1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "-A1LX6-t-hZD",
        "outputId": "3fbb58b2-e9f3-46f4-fbf8-afc6360d5fc6"
      },
      "source": [
        "lalonde1.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>treatment</th>\n",
              "      <th>age</th>\n",
              "      <th>education</th>\n",
              "      <th>black</th>\n",
              "      <th>hispanic</th>\n",
              "      <th>married</th>\n",
              "      <th>RE74</th>\n",
              "      <th>RE75</th>\n",
              "      <th>RE78</th>\n",
              "      <th>pos74</th>\n",
              "      <th>pos75</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>47.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   treatment   age  education  black  hispanic  ...  RE74  RE75  RE78  pos74  pos75\n",
              "0          0  47.0       12.0    0.0       0.0  ...   0.0   0.0   0.0      0      0\n",
              "1          0  50.0       12.0    1.0       0.0  ...   0.0   0.0   0.0      0      0\n",
              "2          0  44.0       12.0    0.0       0.0  ...   0.0   0.0   0.0      0      0\n",
              "3          0  28.0       12.0    1.0       0.0  ...   0.0   0.0   0.0      0      0\n",
              "4          0  54.0       12.0    0.0       0.0  ...   0.0   0.0   0.0      0      0\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 341
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h3_k8av363mT"
      },
      "source": [
        "**Fit Lalonde**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JsP1Gfsi6_mR"
      },
      "source": [
        "RANDOM_SEED = 42\n",
        "np.random.seed(RANDOM_SEED)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APOqpHmrOGzo"
      },
      "source": [
        "confounders = lalonde1.drop(columns=['RE78', 'treatment'])\n",
        "outcome = lalonde1['RE78']\n",
        "treatment = lalonde1['treatment']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eWwSh0jURILr"
      },
      "source": [
        "For reference, compute the naive point estimate of the effect we'd get if don't control for confounding. In this case, there's a negative association between treatment and the outcome (i.e., job training is associated with reduced income)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hYc2ulkuPk3w",
        "outputId": "7df74dbf-8543-4010-d0ee-259c668aba60"
      },
      "source": [
        "outcome[treatment==1].mean()-outcome[treatment==0].mean()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-15204.777468026874"
            ]
          },
          "metadata": {},
          "execution_count": 344
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C576dWRsa3ad"
      },
      "source": [
        "# Specify Nuisance Function Models\n",
        "\n",
        "The next step is to specify models for the conditional expected outcome and propensity score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qyOhSZRQRb8W",
        "outputId": "0c8020c5-424a-4be9-e459-5d0b9aa77299"
      },
      "source": [
        "# specify a model for the conditional expected outcome\n",
        "Q_model = RandomForestRegressor(random_state=RANDOM_SEED, n_estimators=100, max_depth=None)\n",
        "\n",
        "# Sanity check that chosen model actually improves test error\n",
        "# A real analysis should give substantial attention to model selection and validation \n",
        "\n",
        "X_w_treatment = confounders.copy()\n",
        "X_w_treatment[\"treatment\"] = treatment\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_w_treatment, outcome, test_size=0.2)\n",
        "Q_model.fit(X_train, y_train)\n",
        "y_pred = Q_model.predict(X_test)\n",
        "\n",
        "test_mse=mean_squared_error(y_pred, y_test)\n",
        "print(f\"Test MSE of fit model {test_mse}\") \n",
        "baseline_mse=mean_squared_error(y_train.mean()*np.ones_like(y_test), y_test)\n",
        "print(f\"Test MSE of no-covariate model {baseline_mse}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test MSE of fit model 107186056.84174497\n",
            "Test MSE of no-covariate model 246319790.55062827\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uq6eZEBXbsaI",
        "outputId": "a20ac790-0815-4418-f8f5-867b83e93017"
      },
      "source": [
        "# specify a model for the propensity score\n",
        "g_model = RandomForestClassifier(random_state=RANDOM_SEED, n_estimators=100, max_depth=5)\n",
        "\n",
        "# Sanity check that chosen model actually improves test error\n",
        "# A real analysis should give substantial attention to model selection and validation \n",
        "\n",
        "X_train, X_test, a_train, a_test = train_test_split(confounders, treatment, test_size=0.2)\n",
        "g_model.fit(X_train, a_train)\n",
        "a_pred = g_model.predict_proba(X_test)[:,1]\n",
        "\n",
        "test_ce=log_loss(a_test, a_pred)\n",
        "print(f\"Test CE of fit model {test_ce}\") \n",
        "baseline_ce=log_loss(a_test, a_train.mean()*np.ones_like(a_test))\n",
        "print(f\"Test CE of no-covariate model {baseline_ce}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test CE of fit model 0.0789947383398904\n",
            "Test CE of no-covariate model 0.21817471356014154\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2RkvV_4_dFWo"
      },
      "source": [
        "# Use cross fitting to get get predicted outcomes and propensity scores for each unit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KA0AsEGJ_X3b"
      },
      "source": [
        "# helper functions to implement the cross fitting\n",
        "\n",
        "def treatment_k_fold_fit_and_predict(model, X:pd.DataFrame, A:np.array, n_splits:int):\n",
        "    \"\"\"\n",
        "    Implements K fold cross-fitting for the model predicting the treatment A. \n",
        "    That is, \n",
        "    1. Split data into K folds\n",
        "    2. For each fold j, the model is fit on the other K-1 folds\n",
        "    3. The fitted model is used to make predictions for each data point in fold j\n",
        "    Returns an array containing the predictions  \n",
        "\n",
        "    Args:\n",
        "    model: sklearn model, needs to implement fit and predict_prob\n",
        "    X: dataframe of variables to adjust for\n",
        "    A: array of treatments\n",
        "    n_splits: number of splits to use\n",
        "    \"\"\"\n",
        "    predictions = np.full_like(A, np.nan, dtype=float)\n",
        "    kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=RANDOM_SEED)\n",
        "    \n",
        "    for train_index, test_index in kf.split(X, A):\n",
        "      X_train = X.loc[train_index]\n",
        "      A_train = A.loc[train_index]\n",
        "      model.fit(X_train, A_train)\n",
        "\n",
        "      # get predictions for split\n",
        "      predictions[test_index] = model.predict_proba(X.loc[test_index])[:, 1]\n",
        "\n",
        "    assert np.isnan(predictions).sum() == 0\n",
        "    return predictions\n",
        "\n",
        "\n",
        "def outcome_k_fold_fit_and_predict(model, X:pd.DataFrame, y:np.array, A:np.array, n_splits:int, output_type:str):\n",
        "    \"\"\"\n",
        "    Implements K fold cross-fitting for the model predicting the outcome Y. \n",
        "    That is, \n",
        "    1. Split data into K folds\n",
        "    2. For each fold j, the model is fit on the other K-1 folds\n",
        "    3. The fitted model is used to make predictions for each data point in fold j\n",
        "    Returns two arrays containing the predictions for all units untreated, all units treated  \n",
        "\n",
        "    Args:\n",
        "    model: sklearn model, needs to implement fit and either predict_prob or predict\n",
        "    X: dataframe of variables to adjust for\n",
        "    y: array of outcomes\n",
        "    A: array of treatments\n",
        "    n_splits: number of splits to use\n",
        "    output_type: type of outcome, \"binary\" or \"continuous\"\n",
        "\n",
        "    \"\"\"\n",
        "    predictions = np.full_like(A, np.nan, dtype=float)\n",
        "    predictions1 = np.full_like(y, np.nan, dtype=float)\n",
        "    if output_type == 'binary':\n",
        "      kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=RANDOM_SEED)\n",
        "    elif output_type == 'continuous':\n",
        "      kf = KFold(n_splits=n_splits, shuffle=True, random_state=RANDOM_SEED)\n",
        "\n",
        "    # include the treatment as input feature\n",
        "    X_w_treatment = X.copy()\n",
        "    X_w_treatment[\"A\"] = A\n",
        "\n",
        "    # for predicting effect under treatment / control status for each data point \n",
        "    X0 = X_w_treatment.copy()\n",
        "    X0[\"A\"] = 0\n",
        "    X1 = X_w_treatment.copy()\n",
        "    X1[\"A\"] = 1\n",
        "\n",
        "    \n",
        "    for train_index, test_index in kf.split(X_w_treatment, y):\n",
        "      X_train = X_w_treatment.loc[train_index]\n",
        "      y_train = y.loc[train_index]\n",
        "      model.fit(X_train, y_train)\n",
        "\n",
        "      if output_type =='binary':\n",
        "        predictions0[test_index] = model.predict_proba(X0.loc[test_index])[:, 1]\n",
        "        predictions1[test_index] = model.predict_proba(X1.loc[test_index])[:, 1]\n",
        "      elif output_type == 'continuous':\n",
        "        predictions0[test_index] = model.predict(X0.loc[test_index])\n",
        "        predictions1[test_index] = model.predict(X1.loc[test_index])\n",
        "\n",
        "    assert np.isnan(predictions0).sum() == 0\n",
        "    assert np.isnan(predictions1).sum() == 0\n",
        "    return predictions0, predictions1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVcE6pRQeMNf"
      },
      "source": [
        "g = treatment_k_fold_fit_and_predict(g_model, X=confounders, A=treatment, n_splits=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLEHlLLdWSh9"
      },
      "source": [
        "Q0,Q1=k_fold_fit_and_predict_Y(Q_model, X=confounders, y=outcome, A=treatment, n_splits=10, output_type=\"continuous\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "_NVCV0q0g8wQ",
        "outputId": "7f6d0c5d-8947-4a96-a289-37a93280acfa"
      },
      "source": [
        "data_and_nuisance_estimates = pd.DataFrame({'g': g, 'Q0': Q0, 'Q1': Q1, 'A': treatment, 'Y': outcome})\n",
        "data_and_nuisance_estimates.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>g</th>\n",
              "      <th>Q0</th>\n",
              "      <th>Q1</th>\n",
              "      <th>A</th>\n",
              "      <th>Y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.280187</td>\n",
              "      <td>327.275848</td>\n",
              "      <td>2005.302566</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.221749</td>\n",
              "      <td>2460.018120</td>\n",
              "      <td>4178.193550</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.469797</td>\n",
              "      <td>24.561530</td>\n",
              "      <td>2236.205678</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.586396</td>\n",
              "      <td>10551.835256</td>\n",
              "      <td>8920.218158</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.015727</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1633.668328</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          g            Q0           Q1  A    Y\n",
              "0  0.280187    327.275848  2005.302566  0  0.0\n",
              "1  0.221749   2460.018120  4178.193550  0  0.0\n",
              "2  0.469797     24.561530  2236.205678  0  0.0\n",
              "3  0.586396  10551.835256  8920.218158  0  0.0\n",
              "4  0.015727      0.000000  1633.668328  0  0.0"
            ]
          },
          "metadata": {},
          "execution_count": 350
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNhM7URdgzQB"
      },
      "source": [
        "# Combine predicted values and data into estimate of ATT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-vONC5ejwh2"
      },
      "source": [
        "def psi_aiptw(Q0, Q1, g, A, Y, prob_t=None):\n",
        "  \"\"\"\n",
        "  # Double ML estimator for the ATT\n",
        "  This uses the ATT specific scores, see equation 3.9 of https://www.econstor.eu/bitstream/10419/149795/1/869216953.pdf\n",
        "  \"\"\"\n",
        "\n",
        "  if prob_t is None:\n",
        "    prob_t = A.mean() # estimate marginal probability of treatment\n",
        "\n",
        "  tau_hat = (A*(Y-Q0) - (1-A)*(g/(1-g))*(Y-Q0)).mean()/ prob_t\n",
        "  \n",
        "  scores = (A*(Y-Q0) - (1-A)*(g/(1-g))*(Y-Q0) - tau_hat*A) / prob_t\n",
        "  n = Y.shape[0] # number of observations\n",
        "  std_hat = np.std(scores) / np.sqrt(n)\n",
        "\n",
        "  return tau_hat, std_hat\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SjDj0F9Bm9uq",
        "outputId": "b6fe1ced-cb5a-483d-d484-430e5e0b3f98"
      },
      "source": [
        "tau_hat, std_hat = psi_aiptw(**data_and_nuisance_estimates)\n",
        "print(f\"The estimate is {tau_hat} pm {1.96*std_hat}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The estimate is 1265.3429523217906 pm 1577.8958916776455\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IOuJnlbEo8j_",
        "outputId": "3482ed19-62b3-4a02-be29-c8e300a84168"
      },
      "source": [
        "# The LaLonde data has severe overlap issues. Lets try computing the estimate restricted to a population with only reasonable propensity scores\n",
        "in_overlap_popluation = (0.05 < data_and_nuisance_estimates['g'])\n",
        "overlap_data_and_nuisance = data_and_nuisance_estimates[in_overlap_popluation] # only 428 units satisfy this\n",
        "tau_hat, std_hat = psi_aiptw(**overlap_data_and_nuisance)\n",
        "print(f\"The estimate is {tau_hat} pm {1.96*std_hat}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The estimate is 1613.301562438709 pm 1611.0472623428427\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IGz2YVL9rKE9",
        "outputId": "ff96fcc2-906d-4ca7-8143-2621a50b3569"
      },
      "source": [
        "# Finally, lets compare with the naive point estimate using only the Q model\n",
        "# (to get a standard error, we'd need to bootstrap the model fitting)\n",
        "Q1[treatment==1].mean() - Q0[treatment==1].mean()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1050.294554761258"
            ]
          },
          "metadata": {},
          "execution_count": 354
        }
      ]
    }
  ]
}